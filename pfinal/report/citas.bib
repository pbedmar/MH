@online{tacolab,
	title = "TACOlab. \url{https://tacolab.org/bench}",
	author = "Daniel Molina Cabrera"
}

@online{cec_dmolina,
	title = "CEC'2017. \url{https://github.com/dmolina/cec2017real}",
	author = "Daniel Molina Cabrera"
}

@article{EROL2006106,
title = {A new optimization method: Big Bang–Big Crunch},
journal = {Advances in Engineering Software},
volume = {37},
number = {2},
pages = {106-111},
year = {2006},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2005.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0965997805000827},
author = {Osman K. Erol and Ibrahim Eksin},
keywords = {Big Bang–Big Crunch evolution theory, Evolutionary algorithms, Genetic algorithm},
abstract = {Nature is the principal source for proposing new optimization methods such as genetic algorithms (GA) and simulated annealing (SA) methods. All traditional evolutionary algorithms are heuristic population-based search procedures that incorporate random variation and selection. The main contribution of this study is that it proposes a novel optimization method that relies on one of the theories of the evolution of the universe; namely, the Big Bang and Big Crunch Theory. In the Big Bang phase, energy dissipation produces disorder and randomness is the main feature of this phase; whereas, in the Big Crunch phase, randomly distributed particles are drawn into an order. Inspired by this theory, an optimization algorithm is constructed, which will be called the Big Bang–Big Crunch (BB–BC) method that generates random points in the Big Bang phase and shrinks those points to a single representative point via a center of mass or minimal cost approach in the Big Crunch phase. It is shown that the performance of the new (BB–BC) method demonstrates superiority over an improved and enhanced genetic search algorithm also developed by the authors of this study, and outperforms the classical genetic algorithm (GA) for many benchmark test functions.}
}